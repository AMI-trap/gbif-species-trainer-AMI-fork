{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAuthor       : Aditya Jain\\nDate Started : June 14, 2022\\nAbout        : This is the main training file for training the uk moth classifier\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author       : Aditya Jain\n",
    "Date Started : June 14, 2022\n",
    "About        : This is the main training file for training the uk moth classifier\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torchvision.models as torchmodels\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import webdataset as wds\n",
    "\n",
    "from data import dataloader\n",
    "from models.resnet50 import Resnet50\n",
    "from models.models import build_model\n",
    "from data.mothdataset import MOTHDataset\n",
    "from training_params.loss import Loss\n",
    "from training_params.optimizer import Optimizer\n",
    "from evaluation.micro_accuracy_batch import MicroAccuracyBatch\n",
    "from evaluation.micro_accuracy_batch import add_batch_microacc, final_microacc\n",
    "from evaluation.macro_accuracy_batch import MacroAccuracyBatch\n",
    "from evaluation.macro_accuracy_batch import add_batch_macroacc, final_macroacc, taxon_accuracy\n",
    "from evaluation.confusion_matrix_data import confusion_matrix_data\n",
    "from evaluation.confusion_data_conversion import ConfusionDataConvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"note\": \"This config file is for training on the complete macromoths dataset\",\n",
      "   \"model\": {\n",
      "      \"species_num_classes\": 3175,\n",
      "      \"genus_num_classes\": 1088,\n",
      "      \"family_num_classes\": 71,\n",
      "      \"type\": \"resnet50\"\n",
      "   },\n",
      "   \"dataset\": {\n",
      "      \"label_info\": \"/home/mila/a/aditya.jain/gbif_species_trainer/model_training/data/uk-denmark_numeric_labels.json\",\n",
      "      \"taxon_hierarchy\": \"/home/mila/a/aditya.jain/gbif_species_trainer/model_training/data/uk-denmark_taxon_hierarchy.json\"\n",
      "   },\n",
      "   \"training\": {\n",
      "      \"batch_size\": 64,\n",
      "      \"image_resize\": 300,\n",
      "      \"epochs\": 1,\n",
      "      \"early_stopping\": 4,\n",
      "      \"start_val_loss\": 100000000,\n",
      "      \"loss\": {\n",
      "         \"name\": \"crossentropy\"\n",
      "      },\n",
      "      \"optimizer\": {\n",
      "         \"name\": \"sgd\",\n",
      "         \"learning_rate\": 0.001,\n",
      "         \"momentum\": 0.9\n",
      "      },\n",
      "      \"wandb\": {\n",
      "         \"entity\": \"moth-ai\",\n",
      "         \"project\": \"UK-Denmark-Moth-Classifier\"\n",
      "      },\n",
      "      \"model_save_path\": \"/home/mila/a/aditya.jain/logs/\",\n",
      "      \"model_name\": \"uk-denmark-moth-model\",\n",
      "      \"version\": \"v01\"\n",
      "   }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "config_file   = 'config/01-config_uk-denmark.json' #**** This file path should come through command line argument\n",
    "\n",
    "f             = open(config_file)\n",
    "config_data   = json.load(f)\n",
    "print(json.dumps(config_data, indent=3))\n",
    "\n",
    "image_resize  = config_data['training']['image_resize']\n",
    "batch_size    = config_data['training']['batch_size']\n",
    "label_list    = config_data['dataset']['label_info']\n",
    "epochs        = config_data['training']['epochs']\n",
    "loss_name     = config_data['training']['loss']['name']\n",
    "early_stop    = config_data['training']['early_stopping']\n",
    "start_val_los = config_data['training']['start_val_loss']\n",
    "\n",
    "label_read    = json.load(open(label_list))\n",
    "species_list  = label_read['species_list']\n",
    "genus_list    = label_read['genus_list']\n",
    "family_list   = label_read['family_list']\n",
    "\n",
    "no_species_cl = config_data['model']['species_num_classes']\n",
    "no_genus_cl   = config_data['model']['genus_num_classes']\n",
    "no_family_cl  = config_data['model']['family_num_classes']\n",
    "\n",
    "opt_name      = config_data['training']['optimizer']['name']\n",
    "learning_rate = config_data['training']['optimizer']['learning_rate']\n",
    "momentum      = config_data['training']['optimizer']['momentum']\n",
    "\n",
    "mod_save_pth  = config_data['training']['model_save_path']\n",
    "mod_name      = config_data['training']['model_name']\n",
    "mod_ver       = config_data['training']['version']\n",
    "DTSTR         = datetime.datetime.now()\n",
    "DTSTR         = DTSTR.strftime(\"%Y-%m-%d-%H-%M\")\n",
    "save_path     = mod_save_pth + mod_ver + '_' + mod_name + '_' + DTSTR + '.pt'\n",
    "\n",
    "taxon_hierar  = config_data['dataset']['taxon_hierarchy']\n",
    "label_info    = config_data['dataset']['label_info']\n",
    "\n",
    "# wandb.init(project=\"UK Moth Classifier\", entity=\"moth-ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "model = Resnet50(config_data).to(device)\n",
    "# print(model)\n",
    "# print(summary(model, (3,224,224)))  # keras-type model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_url = '/home/mila/a/aditya.jain/scratch/GBIF_Data/webdataset_moths_uk-denmark/train/train-500-000000.tar'\n",
    "val_url = '/home/mila/a/aditya.jain/scratch/GBIF_Data/webdataset_moths_uk-denmark/val/val-500-000000.tar'\n",
    "test_url = '/home/mila/a/aditya.jain/scratch/GBIF_Data/webdataset_moths_uk-denmark/test/test-500-000000.tar'\n",
    "num_workers = 1\n",
    "\n",
    "train_dataloader = dataloader.build_webdataset_pipeline(\n",
    "    sharedurl=train_url,\n",
    "    input_size=image_resize,\n",
    "    batch_size=1,\n",
    "    is_training=True,\n",
    "    num_workers=1)\n",
    "\n",
    "val_dataloader = dataloader.build_webdataset_pipeline(\n",
    "    sharedurl=val_url,\n",
    "    input_size=image_resize,\n",
    "    batch_size=batch_size,\n",
    "    is_training=False,\n",
    "    num_workers=1)\n",
    "\n",
    "\n",
    "test_dataloader = dataloader.build_webdataset_pipeline(\n",
    "    sharedurl=test_url,\n",
    "    input_size=image_resize,\n",
    "    batch_size=batch_size,\n",
    "    is_training=False,\n",
    "    num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Loss function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = Loss(loss_name).func()\n",
    "optimizer = Optimizer(opt_name, model, learning_rate, momentum).func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n",
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:08<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  torch.Size([1, 3175])\n",
      "Truth:  torch.Size([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c2aabe12ba16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutputs\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Truth: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/milamoth/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gbif_species_trainer/model_training/models/resnet50.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/milamoth/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/milamoth/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/milamoth/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/milamoth/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/milamoth/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/milamoth/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/milamoth/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    722\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lowest_val_loss = start_val_los\n",
    "early_stp_count = 0\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss = 0\n",
    "    val_loss   = 0\n",
    "    s_time     = time.time()\n",
    "    \n",
    "    global_microacc_data_train = None\n",
    "    global_microacc_data_val   = None\n",
    "    \n",
    "    ## model training on training dataset\n",
    "    model.train()                      # switching model to training mode\n",
    "    for image_batch, label_batch in train_dataloader:    \n",
    "        image_batch, label_batch = image_batch.to(device), label_batch.to(device)         \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs   = model(image_batch)\n",
    "        print('Output: ', outputs.shape)\n",
    "        print('Truth: ', label_batch.shape)\n",
    "        t_loss    = loss_func(outputs, label_batch)\n",
    "        t_loss.backward()\n",
    "        optimizer.step()        \n",
    "        train_loss += t_loss.item()\n",
    "        \n",
    "        # micro-accuracy calculation\n",
    "        micro_accuracy_train          = MicroAccuracyBatch(outputs, label_batch, label_info, taxon_hierar).batch_accuracy()   \n",
    "        global_microacc_data_train    = add_batch_microacc(global_microacc_data_train, micro_accuracy_train)\n",
    "        \n",
    "    ## model evaluation on validation dataset\n",
    "    model.eval()                       # switching model to evaluation mode\n",
    "    for image_batch, label_batch in val_dataloader:\n",
    "        image_batch, label_batch = image_batch.to(device), label_batch.to(device)\n",
    "        label_batch              = label_batch.squeeze_()        \n",
    "        \n",
    "        outputs   = model(image_batch)        \n",
    "        v_loss    = loss_func(outputs, label_batch)\n",
    "        val_loss += v_loss.item()    \n",
    "        \n",
    "        # micro-accuracy calculation\n",
    "        micro_accuracy_val          = MicroAccuracyBatch(outputs, label_batch, label_info, taxon_hierar).batch_accuracy()   \n",
    "        global_microacc_data_val    = add_batch_microacc(global_microacc_data_val, micro_accuracy_val)\n",
    "    \n",
    "        if val_loss<lowest_val_loss:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss':val_loss}, \n",
    "                save_path)        \n",
    "            lowest_val_loss = val_loss\n",
    "            early_stp_count = 0\n",
    "        else:\n",
    "            early_stp_count += 1        \n",
    "\n",
    "    # logging metrics\n",
    "    wandb.log({'training loss': train_loss, 'validation loss': val_loss})\n",
    "    wandb.log({'training accuracy': (train_corr_pred/train_total_pred)*100,\\\n",
    "               'validation accuracy': (val_corr_pred/val_total_pred)*100}) \n",
    "    \n",
    "    final_micro_accuracy_train = final_microacc(global_microacc_data_train)\n",
    "    final_micro_accuracy_val   = final_microacc(global_microacc_data_val) \n",
    "    wandb.log({'train_micro_species_top1': final_micro_accuracy_train['micro_species_top1'], \n",
    "               'train_micro_genus_top1': final_micro_accuracy_train['micro_genus_top1'],\n",
    "               'train_micro_family_top1': final_micro_accuracy_train['micro_family_top1'],\n",
    "               'val_micro_species_top1': final_micro_accuracy_val['micro_species_top1'], \n",
    "               'val_micro_genus_top1': final_micro_accuracy_val['micro_genus_top1'],\n",
    "               'val_micro_family_top1': final_micro_accuracy_val['micro_family_top1']\n",
    "              })   \n",
    "    \n",
    "    e_time = (time.time()-s_time)/60   # time taken in minutes    \n",
    "    wandb.log({'time per epoch': e_time})\n",
    "    \n",
    "    if early_stp_count >= early_stop:\n",
    "        break    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH       = '/home/mila/a/aditya.jain/logs/v01_mothmodel_2021-06-08-04-53.pt'\n",
    "checkpoint = torch.load(PATH, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# model.load_state_dict(torch.load('logs/mothmodel_2021-05-18-07-36.pt', map_location=device))   #**** Wouldn't need this while running this as a script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()                                          # putting the model in evaluation mode\n",
    "global_microacc_data     = None\n",
    "global_macroacc_data     = None\n",
    "global_confusion_data_sp = None\n",
    "global_confusion_data_g  = None\n",
    "global_confusion_data_f  = None\n",
    "\n",
    "print(\"Prediction on test data started ...\")\n",
    "\n",
    "with torch.no_grad():                                 # switching off gradient computation in evaluation mode\n",
    "    for image_batch, label_batch in test_dataloader:  \n",
    "        image_batch, label_batch = image_batch.to(device), label_batch.to(device)\n",
    "        predictions              = model(image_batch)\n",
    "        \n",
    "        # micro-accuracy calculation\n",
    "        micro_accuracy           = MicroAccuracyBatch(predictions, label_batch, label_info, taxon_hierar).batch_accuracy()   \n",
    "        global_microacc_data     = add_batch_microacc(global_microacc_data, micro_accuracy)\n",
    "        \n",
    "        # macro-accuracy calculation\n",
    "        macro_accuracy           = MacroAccuracyBatch(predictions, label_batch, label_info, taxon_hierar).batch_accuracy()\n",
    "        global_macroacc_data     = add_batch_macroacc(global_macroacc_data, macro_accuracy) \n",
    "        \n",
    "        # confusion matrix\n",
    "        sp_label_batch, sp_predictions, g_label_batch, g_predictions, f_label_batch, f_predictions = ConfusionDataConvert(predictions, label_batch, label_info, taxon_hierar).converted_data()   \n",
    "        \n",
    "        global_confusion_data_sp = confusion_matrix_data(global_confusion_data_sp, [sp_label_batch, sp_predictions])\n",
    "        global_confusion_data_g  = confusion_matrix_data(global_confusion_data_g, [g_label_batch, g_predictions])\n",
    "        global_confusion_data_f  = confusion_matrix_data(global_confusion_data_f, [f_label_batch, f_predictions])        \n",
    "    \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_micro_accuracy            = final_microacc(global_microacc_data)\n",
    "final_macro_accuracy, taxon_acc = final_macroacc(global_macroacc_data)\n",
    "tax_accuracy                    = taxon_accuracy(taxon_acc, label_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving evaluation data to file\n",
    "\n",
    "confdata_pd_f  = pd.DataFrame({'F_Truth': global_confusion_data_f[0].reshape(-1), 'F_Prediction': global_confusion_data_f[1].reshape(-1)})\n",
    "confdata_pd_g  = pd.DataFrame({'G_Truth': global_confusion_data_g[0].reshape(-1), 'G_Prediction': global_confusion_data_g[1].reshape(-1)})\n",
    "confdata_pd_sp = pd.DataFrame({'S_Truth': global_confusion_data_sp[0].reshape(-1), 'S_Prediction': global_confusion_data_sp[1].reshape(-1)})\n",
    "confdata_pd    = pd.concat([confdata_pd_f, confdata_pd_g, confdata_pd_sp], axis=1)\n",
    "\n",
    "confdata_pd.to_csv(mod_save_pth + mod_ver + '_confusion-data.csv', index=False)\n",
    "\n",
    "with open(mod_save_pth + mod_ver + '_micro-accuracy.json', 'w') as outfile:\n",
    "    json.dump(final_micro_accuracy, outfile)\n",
    "\n",
    "with open(mod_save_pth + mod_ver + '_macro-accuracy.json', 'w') as outfile:\n",
    "    json.dump(final_macro_accuracy, outfile)\n",
    "    \n",
    "with open(mod_save_pth + mod_ver + '_taxon-accuracy.json', 'w') as outfile:\n",
    "    json.dump(tax_accuracy, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({'final micro accuracy' : final_micro_accuracy})\n",
    "wandb.log({'final macro accuracy' : final_macro_accuracy})\n",
    "wandb.log({'configuration' : config_data})\n",
    "wandb.log({'tax accuracy' : tax_accuracy})\n",
    "\n",
    "label_f = tf.keras.utils.to_categorical(global_confusion_data_f[0], num_classes=no_family_cl)\n",
    "pred_f  = tf.keras.utils.to_categorical(global_confusion_data_f[1], num_classes=no_family_cl)\n",
    "# experiment.log_confusion_matrix(label_f, pred_f, labels=family_list,\n",
    "#                                 max_example_per_cell=100000,\n",
    "#                                 title=\"Family Confusion Matrix\")\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (milamoth)",
   "language": "python",
   "name": "milamoth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
